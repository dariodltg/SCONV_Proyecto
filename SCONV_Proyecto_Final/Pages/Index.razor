@page "/"
@using Google.Cloud.Dialogflow.V2
@using Google.Protobuf
@using NAudio.Wave
@using Microsoft.JSInterop
@using System.Net
@inject IJSRuntime JS


<PageTitle>Index</PageTitle>

<h1>Bienvenido, inicie su pedido</h1>

<div>
    <div class="row">
        <div class="col" style="background: rgba(0, 0, 200, 0.3); margin:10px; padding:10px" id="zonaPeticionesUsuario">
            <h2 class="alert-heading">Peticiones del usuario</h2>
            <div class="row" style="padding:10px">
                <input class="form-text" type="text" @bind-value="@ultimoInputUsuario">Prueba</input>
                <button class="btn btn-info" @onclick="EnviarFrase">Enviar</button>
                <audio controls id="audioInput">
                    <source id="audioInputUsuario" src="" />
                </audio>
                <section class="main-controls">
                    <canvas id="canvas" class="visualizer" height="60"></canvas>
                    <div id="buttons">
                        <button class="@recordButton" @onclick=Record>Grabar</button>
                        <button class="stop" @onclick=Stop>Parar</button>
                    </div>
                </section>
                <ul class="list-group list-group-numbered" id="listaPeticionesUsuario">
                    @foreach(string input in listaInputsUsuario)
                    {
                        <li>
                            <label>@input</label>
                        </li>
                    }
                </ul>
            </div>          
        </div>
        <div class="col" style="background: rgba(0, 128, 0, 0.3); margin:10px; padding:10px" id="zonaRespuestasDialogflow">
            <h2 class="alert-heading">Respuestas de DialogFlow</h2>
            <div class="row" style="padding:10px">
                <audio controls id="audioRespuesta" >
                    <source id="audioRespuestaSource" src="" />
                </audio>
                <ul class="list-group list-group-numbered" id="listaRespuestasTexto">
                    @foreach(string respuesta in listaRespuestasDialogFlow)
                    {
                        <li>
                            <label>@respuesta</label>
                        </li>
                    }
                </ul>
            </div>           
        </div>
    </div>
</div>

<!--<button @onclick=ReproducirAudio>Probar reproducir</button>-->


@code {
    public string? respuestaDialogFlow { get; set; }
    public string projectId = "sconv-proyecto-370810";
    public string sessionId = "123456789";
    public string languageCode = "es";

    [Parameter] public string? ultimoInputUsuario { get; set; }
    public List<string>? listaInputsUsuario = new List<string>();
    public List<string>? listaRespuestasDialogFlow = new List<string>();

    /// <summary>
    /// Envía a DialogFlow la frase que el usuario ha insertado en la caja de texto.
    /// </summary>
    private async Task EnviarFrase()
    {
        if(ultimoInputUsuario!="" && ultimoInputUsuario != null)
        {
            Utilidades.IncrementarEtapaInteraccion();
            listaInputsUsuario.Add(ultimoInputUsuario);
            SessionsClient sessionsClient = SessionsClient.Create();
            SessionName sesion = new SessionName(projectId, sessionId);
            QueryInput queryInput = new QueryInput();
            queryInput.Text = new TextInput() { Text = ultimoInputUsuario, LanguageCode = languageCode };
            DetectIntentResponse respuesta = await sessionsClient.DetectIntentAsync(sesion, queryInput);
            respuestaDialogFlow = respuesta.QueryResult.FulfillmentText;
            listaRespuestasDialogFlow.Add(respuestaDialogFlow);
            SubirAudio(respuesta);
            await ReproducirAudio();
        }
    }

    /// <summary>
    /// Envía a DialogFlow un audio que el usuario ha grabado.
    /// </summary>
    private async Task<DetectIntentResponse> EnviarAudio()
    {
        Utilidades.IncrementarEtapaInteraccion();
        SessionsClient sessionsClient = SessionsClient.Create();
        SessionName sesion = new SessionName(projectId, sessionId);
        QueryInput queryInput = new QueryInput();
        queryInput.AudioConfig = new InputAudioConfig()
            {
                AudioEncoding = AudioEncoding.Linear16,
                LanguageCode = languageCode,
                SampleRateHertz = 44100
            };
        DetectIntentRequest peticion = new DetectIntentRequest();
        peticion.SessionAsSessionName = sesion;
        peticion.QueryInput = queryInput;

        var formato = new WaveFormat(44100, 16, 1);
        string rutaWav = "grabacion_usuario_"+Utilidades.etapaInteraccion+".wav";
        while (!File.Exists("audios/"+rutaWav))
        {
            Thread.Sleep(50);
        }
        using (WaveFileReader reader = new WaveFileReader("audios/"+rutaWav))
        {
            using (var resampler = new MediaFoundationResampler(reader, formato))
            {
                WaveFileWriter.CreateWaveFile("audios/resampleado_" + rutaWav, resampler);
            }
        }

        using (WaveFileReader reader = new WaveFileReader("audios/resampleado_" + rutaWav))
        {
            byte[] buffer = new byte[reader.Length];
            int read = reader.Read(buffer, 0, buffer.Length);
            short[] sampleBuffer = new short[read / 2];
            Buffer.BlockCopy(buffer, 0, sampleBuffer, 0, read);
            peticion.InputAudio = ByteString.CopyFrom(buffer);
        }

        DetectIntentResponse respuesta = await sessionsClient.DetectIntentAsync(peticion);
        return respuesta;
    }

    string recordButton = "grabar";
    bool recording = false;
    bool notRecording = true;

    /// <summary>
    /// Inicia la grabación de un audio del usuario
    /// </summary>
    private async Task Record()
    {
        recordButton = "grabando";
        recording = true;
        notRecording = false;
        await JS.InvokeVoidAsync("startRecording");
    }

    /// <summary>
    /// Detiene la grabación de un audio del usuario
    /// </summary>
    /// <returns></returns>
    private async Task Stop()
    {
        recordButton = "grabar";
        recording = false;
        notRecording = true;
        await JS.InvokeVoidAsync("stopRecording");
        DetectIntentResponse respuestaAudio = await EnviarAudio();


        listaInputsUsuario.Add(respuestaAudio.QueryResult.QueryText);
        listaRespuestasDialogFlow.Add(respuestaAudio.QueryResult.FulfillmentText);
        SubirAudio(respuestaAudio);
        await ReproducirAudio();
    }

    private void SubirAudio(DetectIntentResponse respuestaAudio)
    {
        byte[] buffer = respuestaAudio.OutputAudio.ToByteArray();
        var formato = new WaveFormat(24000, 16, 1);
        string nombreWav = "grabacion_dialogflow_" + Utilidades.etapaInteraccion + ".wav";
        using (WaveFileWriter writer = new WaveFileWriter("audios/"+nombreWav, formato))
        {
            writer.Write(buffer, 0, buffer.Length);
        };

        //Upload to wwwroot
        System.IO.Directory.CreateDirectory("wwwroot/audios/");
        using var stream = new MemoryStream(File.ReadAllBytes("audios/"+nombreWav).ToArray());
        var formFile = new FormFile(stream, 0, stream.Length, "streamFile", "audios/"+nombreWav);
        var fileName = Path.GetFileName(formFile.FileName);
        var filePath = Path.Combine(Directory.GetCurrentDirectory(), @"wwwroot/audios/", fileName);
        using (var fileStream = new FileStream(filePath, FileMode.Create))
        {
            formFile.CopyTo(fileStream);
        }
    }

    async Task ReproducirAudio()
    {
        string nombreWav = "grabacion_dialogflow_" + Utilidades.etapaInteraccion + ".wav";
        await JS.InvokeVoidAsync("ReproducirRespuestaAudio", "audios/"+nombreWav);
    }
}